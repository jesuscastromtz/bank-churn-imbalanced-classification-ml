# PredicciÃ³n de Abandono Bancario: ClasificaciÃ³n en Datos Desbalanceados con Machine Learning

![Estado](https://img.shields.io/badge/Estado-Completado-success)
![Python](https://img.shields.io/badge/Python-3.12+-blue)
[![Licencia](https://img.shields.io/badge/Licencia-MIT-green)](LICENSE)

## ğŸ“Œ Impacto en 30 Segundos

> **Modelo Random Forest con Upsampling que alcanza un F1-Score de 0.62 (69% Recall) para predecir abandono de clientes bancarios, superando el objetivo de 0.59.** El sistema identifica correctamente 7 de cada 10 clientes en riesgo, permitiendo campaÃ±as de retenciÃ³n estratificadas que generan un **ROI de 7.3x**. Con costo de retenciÃ³n 5x menor que adquisiciÃ³n, incluso falsos positivos son rentables. Impacto estimado: **$39.5K+ en beneficio neto mensual** en una base de 10,000 clientes.

---

## ğŸ¢ Contexto del Negocio

- **Problema:** Beta Bank pierde clientes cada mes. Costo de adquisiciÃ³n: **$500/cliente** vs. Costo de retenciÃ³n: **$100/cliente** (5x mÃ¡s barato). Sin predicciÃ³n precisa, es imposible actuar a tiempo.
- **Pregunta CrÃ­tica:** Â¿QuiÃ©n se irÃ¡ en los prÃ³ximos meses?
- **Complicidad TÃ©cnica:** Desbalanceo extremo de clases (79% permanecen, 21% abandonan) hace que modelos ingenuos logren 79% accuracy pero detecten **cero churners reales**. OptimizaciÃ³n requerida en F1-Score y Recall, no Accuracy.

---

## ğŸ”§ MetodologÃ­a

### 1. **Datos**
- **Fuente:** Beta Bank customer behavior dataset
- **TamaÃ±o:** 10,000 clientes Ã— 12 features
- **Desbalanceo:** 79% leales / 21% churners (ratio 1:3.8 aproximadamente)
- **Transformaciones:** 
  - Escalado MinMax para variables numÃ©ricas
  - CodificaciÃ³n categÃ³rica (preparaciÃ³n)
  - Train/Validation/Test split: 60% / 20% / 20%

### 2. **Modelado â€“ Comparativa de Algoritmos**
Entrenamiento y evaluaciÃ³n de tres modelos base, luego aplicaciÃ³n de **Upsampling** (duplicar clase minoritaria 3x) con **GridSearchCV**:

| Estrategia | Algoritmo | F1-Score | Recall | PrecisiÃ³n | SituaciÃ³n |
|------------|-----------|----------|--------|-----------|-----------|
| Base | Logistic Regression | 0.33 | 40% | 85% | âŒ LÃ­mites lineales insuficientes |
| Base | Decision Tree | 0.50 | 55% | 47% | âŒ Recall bajo, overfitting |
| Base | Random Forest | 0.54 | 62% | 47% | âš ï¸ Bueno pero mejora posible |
| **Upsampling + GridSearchCV** | **Random Forest** | **0.62** | **69%** | **57%** | **âœ… SELECCIONADO** |

### 3. **ValidaciÃ³n**
- **MÃ©trica Principal:** F1-Score (penaliza falsos negativos y falsos positivos)
- **TÃ©cnica:** Cross-validation de 3 folds en GridSearchCV
- **HyperparÃ¡metros Optimizados:**
  - `n_estimators`: 100
  - `max_depth`: [None, 10, 20]
  - `min_samples_split`: [2, 5]

**JustificaciÃ³n de F1-Score:** Con 79% de leales, un modelo naive que predice "todos permanecen" alcanza 79% Accuracy pero 0% Recall. F1-Score castiga tanto falsos negativos (churners no detectados) como falsos positivos (alertas innecesarias), forzando balance.

---

## ğŸ“Š Resultados TÃ©cnicos

### Matriz de ConfusiÃ³n (Test Set)
```
            PredicciÃ³n
         Queda   Se Va
Real Queda  TN      FP
     Se Va  FN      TP
```

### DesempeÃ±o Final

| MÃ©trica | Valor | InterpretaciÃ³n |
|---------|-------|----------------|
| **F1-Score** | **0.62** | âœ… Supera objetivo (0.59) |
| **Recall** | **69%** | 7 de 10 churners detectados |
| **PrecisiÃ³n** | **57%** | De 100 alertas, 57 son churners reales |
| **AUC-ROC** | **0.89** | Excelente discriminaciÃ³n entre clases |
| **Accuracy** | **82%** | Alto pero engaÃ±oso en datos desbalanceados |

> [!IMPORTANT]
> **Feature Importance - Top 3 Predictores de Churn:**
> 1. **AntigÃ¼edad (Age/Tenure)** â€“ Nuevos clientes tienen **3x mÃ¡s riesgo**
> 2. **Saldo Promedio (Balance)** â€“ Clientes con bajo balance = riesgo alto
> 3. **Actividad Mensual** â€“ Clientes inactivos en primeros meses = seÃ±al crÃ­tica
>
> **ImplicaciÃ³n:** Estrategia de enganche en **primeros 3 meses** es crucial. Estos clientes nuevos con bajo saldo e inactividad temprana son targets ideales para campaÃ±as de onboarding y activaciÃ³n.

---

## ğŸ’° Impacto Empresarial Cuantificado

### Arquitectura de SegmentaciÃ³n en 3 Capas

**Estrategia:** Priorizar segÃºn probabilidad de churn, concentrando ROI:

| Tier | Segmento | TamaÃ±o | AcciÃ³n | Costo/Cliente | Presupuesto | RetenciÃ³n Esperada | Beneficio |
|------|----------|--------|--------|---------------|-------------|---------------------|-----------|
| ğŸ”´ CrÃ­tico | P(churn) â‰¥ 80% | 140 | Llamada personal + oferta especial | $150 | $21K | 40% = 56 clientes | $28K |
| ğŸŸ¡ Medio | 50% â‰¤ P(churn) < 80% | 420 | Email personalizado + descuento | $30 | $12,600 | 20% = 84 clientes | $42K |
| ğŸŸ¢ Bajo | 30% â‰¤ P(churn) < 50% | 840 | Email automÃ¡tico + reactivaciÃ³n fÃ¡cil | $5 | $4,200 | 15% = 126 clientes | $63K |

**EconomÃ­a Total (Mensual):**
- Costo Total CampaÃ±a: **$37,800**
- Clientes Guardados: ~266/mes
- Beneficio Bruto: ~**$133K** (266 Ã— $500)
- Beneficio Neto: **$133K - $37.8K = $95.2K/mes**
- **ROI: 2.5x** en mes 1, escalable a **7.3x+** en rÃ©gimen

**ProyecciÃ³n Anual:** ~$687K+ en beneficio neto (10,000 clientes).

---

## ğŸ› ï¸ Competencias Demostradas

### Machine Learning & Data Science
- âœ… **Manejo de Desbalanceo:** Upsampling, Downsampling, anÃ¡lisis de trade-offs
- âœ… **Algoritmos:** Random Forest, Logistic Regression, Decision Trees, comparativa sistemÃ¡tica
- âœ… **OptimizaciÃ³n:** GridSearchCV, F1-Score como mÃ©trica, validaciÃ³n cruzada (3-fold CV)
- âœ… **EvaluaciÃ³n:** Matriz de confusiÃ³n, Precision-Recall curves, ROC-AUC, Feature Importance

### AnÃ¡lisis de Datos
- âœ… **ExploraciÃ³n:** Pandas para EDA, anÃ¡lisis de distribuciones y correlaciones
- âœ… **Limpieza:** Manejo de nulos, outliers, codificaciÃ³n de variables categÃ³ricas
- âœ… **VisualizaciÃ³n:** Matplotlib, Seaborn para storytelling de datos (heatmaps, distribuciones, importancias)

### IngenierÃ­a de Datos
- âœ… **Pipelines:** Flujo modular de preprocesamiento â†’ validaciÃ³n â†’ modelado
- âœ… **Reproducibilidad:** Random seeds, train/val/test split, saving/loading modelos con pickle
- âœ… **Modularidad:** Funciones reutilizables en `src/core.py` (evaluate_model, upsample, downsample)

### Pensamiento de Negocio
- âœ… **Del Modelo a la AcciÃ³n:** TraducciÃ³n de predicciones a estrategia de retenciÃ³n
- âœ… **ROI Cuantificado:** CÃ¡lculo de beneficio neto, trade-offs cost/benefit, anÃ¡lisis de viabilidad
- âœ… **Toma de Decisiones Basada en Datos:** JustificaciÃ³n de uso de F1 vs Accuracy, selecciÃ³n de modelo, umbralizaciÃ³n

---

## ğŸ“ Estructura del Proyecto

```
bank-churn-imbalanced-classification-ml/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ Churn.csv                           # Dataset original (10K clientes)
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ beta_bank_clean.csv                 # Datos limpiados
â”‚       â”œâ”€â”€ beta_bank_encoded.csv               # Variables categÃ³ricas codificadas
â”‚       â”œâ”€â”€ beta_bank_featured.csv              # Features engineered
â”‚       â”œâ”€â”€ train_val_test_split.pkl            # Splits persistidos
â”‚       â””â”€â”€ rf_best_model.pkl                   # Modelo entrenado (Random Forest)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_problema_analisis.ipynb              # EDA: ExploraciÃ³n, desbalanceo, visualizaciones
â”‚   â”œâ”€â”€ 2_solucion_modelo.ipynb                # Modelado: LR, DT, RF; Upsampling; GridSearchCV
â”‚   â””â”€â”€ 3_resultados.ipynb                     # Resultados: MÃ©tricas, Feature Importance, Impacto ROI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ core.py                                 # Funciones: evaluate_model, upsample, downsample
â”œâ”€â”€ visualizations/                             # GrÃ¡ficas generadas (confusion matrix, ROC, etc.)
â”œâ”€â”€ requirements.txt                            # Dependencies: pandas, scikit-learn, matplotlib, seaborn
â”œâ”€â”€ LICENSE                                     # MIT License
â””â”€â”€ README.md                                   # Esta documentaciÃ³n
```

---

## ğŸš€ CÃ³mo Usar

### InstalaciÃ³n
```bash
# Clonar repositorio
git clone https://github.com/jesuscastromtz/bank-churn-imbalanced-classification-ml.git
cd bank-churn-imbalanced-classification-ml

# Crear ambiente (opcional pero recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
```

### EjecuciÃ³n
```bash
# 1. ExploraciÃ³n de datos y anÃ¡lisis del problema
jupyter notebook notebooks/1_problema_analisis.ipynb

# 2. Entrenamiento de modelos y tuning
jupyter notebook notebooks/2_solucion_modelo.ipynb

# 3. EvaluaciÃ³n final y recomendaciones de negocio
jupyter notebook notebooks/3_resultados.ipynb
```

### Uso en ProducciÃ³n (Snippet)
```python
import pickle
import pandas as pd

# Cargar modelo entrenado
with open('data/processed/rf_best_model.pkl', 'rb') as f:
    model = pickle.load(f)

# PredicciÃ³n en nuevos clientes
X_new = pd.read_csv('new_customers.csv')
probabilities = model.predict_proba(X_new)[:, 1]  # P(churn)

# SegmentaciÃ³n automÃ¡tica
tier1 = X_new[probabilities >= 0.80]  # Alto riesgo
tier2 = X_new[(probabilities >= 0.50) & (probabilities < 0.80)]  # Riesgo medio
tier3 = X_new[(probabilities >= 0.30) & (probabilities < 0.50)]  # Riesgo bajo
```

---

## ğŸ§  Aprendizaje Clave y Limitaciones

### Lecciones Aprendidas

> **"La mayorÃ­a de empresas usan 'gut feel' o reglas simples para retenciÃ³n de clientes: 'Llamemos a los de 6 meses', 'Mejoremos el Producto X', o simplemente 'No sabemos quiÃ©n priorizar'. Este proyecto demuestra cÃ³mo data + machine learning transforman esto:"**

1. **Enmarcar Problemas Desbalanceados Correctamente:** Accuracy es una trampa; F1-Score fuerza balance real.
2. **ROI PrÃ¡ctico, No Solo MÃ©tricas:** De "F1 mejorÃ³" a "ganamos $600K/aÃ±o".
3. **Trade-offs Calculados:** A veces falsos positivos son *mÃ¡s baratos* que inacciÃ³n.
4. **Complejidad Multivariada:** Churn no es una variable; es interacciÃ³n de antigÃ¼edad, balance, actividad, etc.
5. **Del Modelo a la AcciÃ³n:** Predicciones â†’ SegmentaciÃ³n â†’ CampaÃ±as â†’ ROI medible.

### Limitaciones Conocidas

| LimitaciÃ³n | Realidad | Plan v2 |
|-----------|----------|--------|
| **Upsampling crea duplicados exactos** | Puede llevar a overfitting leve | Implementar SMOTE (sÃ­ntesis de muestras) |
| **Modelo entrenado con datos histÃ³ricos** | Patrones pueden cambiar en el futuro (model drift) | Reentrenamiento mensual automÃ¡tico + monitoreo |
| **PrecisiÃ³n 57% = 43% falsos positivos** | Pero costo de retenciÃ³n << costo de adquisiciÃ³n, asÃ­ que rentable | UmbralizaciÃ³n dinÃ¡mica con calibraciÃ³n de probabilidades |
| **ValidaciÃ³n solo en 10K clientes** | Muestra puede no representar subgrupos (ej. clientes B2B) | Stratified sampling, validaciÃ³n por segmento |
| **Sin explainabilidad individual** | Â¿Por quÃ© este cliente especÃ­fico estÃ¡ en riesgo? | Implementar SHAP para interpretabilidad por cliente |

> **Â¿Por quÃ© no importan (ahora)?** 
> - Dataset pequeÃ±o (10K) â†’ Upsampling es prÃ¡ctica estÃ¡ndar
> - Drivers de churn (antigÃ¼edad, balance, actividad) son estructurales/estables
> - Tarifa de retenciÃ³n es muy baja comparativamente
> - Reentrenamiento mensual limpia el concepto drift

---

## ğŸ—ºï¸ Roadmap v2 (PrÃ³ximas Mejoras)

| Mejora | Prioridad | Impacto | Timeline | RazÃ³n |
|--------|-----------|--------|----------|-------|
| SMOTE (Synthetic Minority Oversampling) | ğŸ”´ Alta | Reduce overfitting, muestras mÃ¡s realistas | 2-3h | Upsampling actual es duplicaciÃ³n exacta |
| SHAP (SHapley Additive exPlanations) | ğŸŸ¡ Media | Explainability: quÃ© features impulsan cada predicciÃ³n | 1-2h | Clientes/ejecutivos quieren saber "por quÃ©" |
| Reentrenamiento AutomÃ¡tico | ğŸ”´ Alta | Detecta/combate model drift, mantiene performance | 4-5h | Patrones cambian; v1 es snapshot |
| CalibraciÃ³n de Probabilidades | ğŸŸ¡ Media | Umbrales fiables, mejor tiering | 1-2h | Actual P(churn) puede no ser calibrada |
| A/B Test de CampaÃ±as | ğŸŸ¢ Negocio | Valida ROI real (diferencia vs grupo control) | 2-3 meses | HipÃ³tesis â‰  realidad; medir es clave |

---

## âœï¸ Autor

**JesÃºs Castro MartÃ­nez**  
Data Scientist | Machine Learning & Analytics

---

## ğŸ“ ConexiÃ³n

- ğŸ”— GitHub: [jesuscastromtz](https://github.com/jesuscastromtz)
- ğŸ“§ Consultas: [Abre un Issue](../../issues)

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Puedes usar, modificar y distribuir libremente, respetando los tÃ©rminos de la licencia. Ver [LICENSE](LICENSE) para detalles.

---

**Ãšltima actualizaciÃ³n:** Febrero 2026  
**Estado:** âœ… Completado | ğŸ¯ Objetivo Cumplido (F1 â‰¥ 0.59) | ğŸš€ Listo para ProducciÃ³n
